{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add a dropout probability for tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def array_to_one_hot(lable):\n",
    "    # input lable is list\n",
    "    new_lable =  []\n",
    "    lables =  sorted(set(lable))    \n",
    "    for i in lable:\n",
    "        single_lable = [0] * len(lables)\n",
    "        index = lables.index(i)\n",
    "        single_lable[index] = 1\n",
    "        new_lable.append(single_lable)\n",
    "    return np.array(new_lable)\n",
    "\n",
    "def fake_label_to_real_label_array(fake_label, labels):\n",
    "    real_label_array = []\n",
    "    for i in fake_label:\n",
    "        real_label_array.append(labels[i])\n",
    "    return np.array(real_label_array)\n",
    "\n",
    "def one_hot_to_array(labels):\n",
    "    new_label = []\n",
    "    for label in labels:\n",
    "        index = label.tolist().index(1)\n",
    "        new_label.append(index)\n",
    "    return new_label\n",
    "\n",
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "\n",
    "feature_name = train.columns[1:] \n",
    "label_name = train.columns[0] #put the class label on the first column\n",
    "\n",
    "train_feature = train[feature_name].as_matrix()\n",
    "test_feature = test[feature_name].as_matrix()\n",
    "\n",
    "train_label_one_hot = array_to_one_hot(train[label_name].tolist()) #tensorflow must use one-hot form\n",
    "test_label_one_hot = array_to_one_hot(test[label_name].tolist())\n",
    "\n",
    "train_label_array = np.array(train[label_name])\n",
    "test_label_array = np.array(test[label_name])\n",
    "\n",
    "labels = sorted(set(train[label_name].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_feature.shape)\n",
    "print(train_label_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## compelet of preparing the data\n",
    "learning_rate = 0.005\n",
    "training_period = 20\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 400 # 1st layer number of features\n",
    "n_hidden_2 = 200 # 2nd layer number of features\n",
    "n_input = train_feature.shape[1]\n",
    "n_classes = train_label_one_hot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# difine keep probability\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variable\n",
    "w1 = tf.Variable(tf.truncated_normal([n_input, n_hidden_1],stddev=1))\n",
    "w2 = tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],stddev=0.1))\n",
    "w3 = tf.Variable(tf.truncated_normal([n_hidden_2, n_classes],stddev=0.1))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([n_hidden_1])+0.1)\n",
    "b2 = tf.Variable(tf.zeros([n_hidden_2])+0.1)\n",
    "b3 = tf.Variable(tf.zeros([n_classes])+0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add layer with dropout probability\n",
    "layer_1 = tf.add(tf.matmul(x, w1), b1)\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "layer_1_drop = tf.nn.dropout(layer_1,keep_prob)\n",
    "# Hidden layer with RELU activation\n",
    "layer_2 = tf.add(tf.matmul(layer_1_drop, w2), b2)\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "layer_2_drop = tf.nn.dropout(layer_2,keep_prob)\n",
    "# Output layer with linear activation\n",
    "pred = tf.add(tf.matmul(layer_2_drop, w3), b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# defined next_batch function\n",
    "def next_batch(round_num,sample_num, data):\n",
    "    # Return a total of `num` samples from the array `data`. \n",
    "    return data[sample_num*round_num:sample_num*(round_num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period 0 trian: 0.2055 test: 0.2115\n",
      "period 1 trian: 0.2682 test: 0.272\n",
      "period 2 trian: 0.3175 test: 0.3125\n",
      "period 3 trian: 0.4258 test: 0.424\n",
      "period 4 trian: 0.6125 test: 0.6065\n",
      "period 5 trian: 0.5829 test: 0.579\n",
      "period 6 trian: 0.7581 test: 0.751\n",
      "period 7 trian: 0.8018 test: 0.803\n",
      "period 8 trian: 0.8583 test: 0.858\n",
      "period 9 trian: 0.9144 test: 0.915\n",
      "period 10 trian: 0.9448 test: 0.95\n",
      "period 11 trian: 0.9629 test: 0.9615\n",
      "period 12 trian: 0.976 test: 0.9765\n",
      "period 13 trian: 0.9826 test: 0.982\n",
      "period 14 trian: 0.9862 test: 0.986\n",
      "period 15 trian: 0.99 test: 0.989\n",
      "period 16 trian: 0.9935 test: 0.9925\n",
      "period 17 trian: 0.9947 test: 0.9945\n",
      "period 18 trian: 0.9962 test: 0.9955\n",
      "period 19 trian: 0.997 test: 0.9965\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for k in range(training_period):\n",
    "        total_batch = int(train_feature.shape[0]/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x = next_batch(i,batch_size,train_feature)\n",
    "            batch_y = next_batch(i,batch_size,train_label_one_hot)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer,feed_dict={x:batch_x,y:batch_y,keep_prob:0.9})\n",
    "        # Display logs per epoch step\n",
    "        if k % display_step == 0:\n",
    "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            \n",
    "            test_accuracy = accuracy.eval({x: test_feature, y: test_label_one_hot,keep_prob:1})\n",
    "            train_accuarcy = accuracy.eval({x: train_feature, y: train_label_one_hot,keep_prob:1})\n",
    "            print(\"period %d\" %k,\"trian:\", train_accuarcy, \"test:\" ,test_accuracy)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    # get accuarcy\n",
    "    test_accuracy = accuracy.eval({x: test_feature, y: test_label_one_hot,keep_prob:1})\n",
    "    train_accuarcy = accuracy.eval({x: train_feature, y: train_label_one_hot,keep_prob:1})\n",
    "    \n",
    "    test_acc = sess.run(accuracy,feed_dict={x: test_feature, y: test_label_one_hot,keep_prob:1.0})\n",
    "    train_acc = sess.run(accuracy,feed_dict={x: test_feature, y: test_label_one_hot,keep_prob:1.0})\n",
    "    # get probability matrix\n",
    "    soft_y = tf.nn.softmax(pred)\n",
    "    test_pred_prob_matrix = sess.run(soft_y,feed_dict={x: test_feature,keep_prob:1.0})\n",
    "    train_pred_prob_matrix = sess.run(soft_y,feed_dict={x: train_feature,keep_prob:1.0})\n",
    "    \n",
    "    # get predicted index\n",
    "    test_pred_index = sess.run(tf.argmax(pred, 1), feed_dict={x: test_feature,keep_prob:1.0})\n",
    "    train_pred_index = sess.run(tf.argmax(pred, 1), feed_dict={x: train_feature,keep_prob:1.0})\n",
    "    \n",
    "    # get predicted label\n",
    "    test_pred_label_array = fake_label_to_real_label_array(np.array(test_pred_index.tolist()), labels) #list form\n",
    "    train_pred_label_array = fake_label_to_real_label_array(np.array(train_pred_index.tolist()), labels) #list form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accuarcy: 0.997\n",
      "train_acc: 0.9965\n",
      "test_accuracy: 0.9965\n",
      "test_acc 0.9965\n"
     ]
    }
   ],
   "source": [
    "# here we use two ways to get train and test accuarcy\n",
    "print(\"train_accuarcy:\",train_accuarcy)\n",
    "print(\"train_acc:\",train_acc)\n",
    "\n",
    "print(\"test_accuracy:\",test_accuracy)\n",
    "print(\"test_acc\",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_pred_prob_matrix: [[  7.69217372e-01   2.90796655e-04   2.11394921e-01 ...,   7.71797216e-03\n",
      "    8.86517402e-04   9.85388062e-04]\n",
      " [  1.00000000e+00   1.45292780e-23   8.31150285e-17 ...,   9.04535098e-31\n",
      "    6.10369850e-38   8.30425613e-37]\n",
      " [  1.00000000e+00   5.16882177e-34   2.98243372e-29 ...,   2.06480723e-37\n",
      "    8.74148305e-29   0.00000000e+00]\n",
      " ..., \n",
      " [  5.53881364e-06   1.90445206e-08   1.42951446e-08 ...,   1.80008810e-05\n",
      "    5.72615058e-08   9.99972343e-01]\n",
      " [  1.98734227e-07   2.79165691e-09   6.09270279e-09 ...,   2.30011005e-06\n",
      "    2.80512324e-09   9.99996066e-01]\n",
      " [  1.24967059e-07   1.06815690e-09   1.41931314e-10 ...,   3.17005693e-08\n",
      "    3.09972337e-09   9.99994636e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"test_pred_prob_matrix:\",test_pred_prob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
