{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use mnist data to perform CNN network.\n",
    "In this example, I use the following CNN structure:\n",
    "    5*5*32, max_pooling, 5*5*64, max_pooling, 1024 fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the function we use\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.zeros(shape)+0.1\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def get_conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def max_pool(x,ksize):\n",
    "    return tf.nn.max_pool(x,ksize,strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "def next_batch(round_num,sample_num,data):\n",
    "    total_batch = len(data)//sample_num\n",
    "    round_num = round_num % total_batch\n",
    "    return data[sample_num*round_num:sample_num*(round_num+1)]\n",
    "\n",
    "def array_to_one_hot(all_lables,lables):\n",
    "    # input lable is list\n",
    "    new_lable =  [] \n",
    "    for i in all_lables:\n",
    "        single_lable = [0] * len(lables)\n",
    "        index = lables.index(i)\n",
    "        single_lable[index] = 1\n",
    "        new_lable.append(single_lable)\n",
    "    return np.array(new_lable)\n",
    "\n",
    "def fake_label_to_real_label_array(fake_label, labels):\n",
    "    real_label_array = []\n",
    "    for i in fake_label:\n",
    "        real_label_array.append(labels[i])\n",
    "    return np.array(real_label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "# shuffle the data\n",
    "train = train.sample(frac=1)\n",
    "\n",
    "feature_name = train.columns[1:] \n",
    "label_name = train.columns[0] #put the class label on the first column\n",
    "\n",
    "train_feature = train[feature_name].as_matrix()\n",
    "test_feature = test[feature_name].as_matrix()\n",
    "\n",
    "labels = sorted(set(train[label_name].tolist()))\n",
    "\n",
    "train_label_one_hot = array_to_one_hot(train[label_name].tolist(),labels) #tensorflow must use one-hot form\n",
    "test_label_one_hot = array_to_one_hot(test[label_name].tolist(),labels)\n",
    "\n",
    "train_label_array = np.array(train[label_name])\n",
    "test_label_array = np.array(test[label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "15    1000\n",
      "14    1000\n",
      "13    1000\n",
      "12    1000\n",
      "19    1000\n",
      "11    1000\n",
      "18    1000\n",
      "10    1000\n",
      "17    1000\n",
      "16    1000\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_feature.shape)\n",
    "print(train[label_name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define all the parameters\n",
    "learning_rate_start = 0.0001\n",
    "training_period = 1501\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "\n",
    "image_reshape = [-1,28,28,1]\n",
    "n_input = train_feature.shape[1]\n",
    "n_classes = train_label_one_hot.shape[1]\n",
    "conv1_stru = [5,5,1,32]\n",
    "conv2_stru = [5,5,32,64]\n",
    "pool1_ksize = [1,2,2,1]\n",
    "pool2_ksize = [1,2,2,1]\n",
    "pool2_flat = [-1,7*7*64]\n",
    "fc1_stru = [7*7*64,1024]\n",
    "fc2_stru = [1024,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the net work\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(x,image_reshape)\n",
    "\n",
    "w_conv1 = weight_variable(conv1_stru)\n",
    "w_conv2 = weight_variable(conv2_stru)\n",
    "w_fc1 = weight_variable(fc1_stru)\n",
    "w_fc2 = weight_variable(fc2_stru)  \n",
    "\n",
    "b_conv1 = bias_variable([conv1_stru[-1]])\n",
    "b_conv2 = bias_variable(conv2_stru[-1])\n",
    "b_fc1 = bias_variable([fc1_stru[-1]])\n",
    "b_fc2 = bias_variable([fc2_stru[-1]])\n",
    "\n",
    "# convolution layer 1\n",
    "conv_1 = get_conv2d(x_image,w_conv1) + b_conv1\n",
    "conv_1 = tf.nn.relu(conv_1)\n",
    "# maxpooling layer 1\n",
    "pool_1 = max_pool(conv_1,pool1_ksize)\n",
    "\n",
    "# convolution layer 2\n",
    "conv_2 = get_conv2d(pool_1,w_conv2) + b_conv2\n",
    "conv_2 = tf.nn.relu(conv_2)\n",
    "\n",
    "pool_2 = max_pool(conv_2,pool2_ksize)\n",
    "\n",
    "pool_2_flat = tf.reshape(pool_2,pool2_flat)\n",
    "\n",
    "fc_1 = tf.matmul(pool_2_flat,w_fc1) + b_fc1\n",
    "fc_1_act = tf.nn.relu(fc_1)\n",
    "fc_1_drop = tf.nn.dropout(fc_1_act,keep_prob)\n",
    "\n",
    "fc_2 = tf.matmul(fc_1_drop,w_fc2) + b_fc2\n",
    "fc_2_act = tf.nn.relu(fc_2)\n",
    "fc_2_drop = tf.nn.dropout(fc_2_act,keep_prob)\n",
    "\n",
    "pred = tf.nn.softmax(fc_2_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define loss and \n",
    "batch = tf.Variable(0)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate_start,\n",
    "                                            training_period,\n",
    "                                            10000,\n",
    "                                            0.95,\n",
    "                                            staircase=True)\n",
    "\n",
    "loss= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss,global_step=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period 0 trian: 0.0748 test: 0.075\n",
      "period 100 trian: 0.6318 test: 0.629\n",
      "period 200 trian: 0.7474 test: 0.7415\n",
      "period 300 trian: 0.7613 test: 0.758\n",
      "period 400 trian: 0.9361 test: 0.9355\n",
      "period 500 trian: 0.9553 test: 0.9555\n",
      "period 600 trian: 0.9582 test: 0.958\n",
      "period 700 trian: 0.9679 test: 0.968\n",
      "period 800 trian: 0.9702 test: 0.9735\n",
      "period 900 trian: 0.975 test: 0.9745\n",
      "period 1000 trian: 0.9781 test: 0.978\n",
      "period 1100 trian: 0.9791 test: 0.9775\n",
      "period 1200 trian: 0.9829 test: 0.983\n",
      "period 1300 trian: 0.983 test: 0.982\n",
      "period 1400 trian: 0.9858 test: 0.9875\n",
      "period 1500 trian: 0.9854 test: 0.9855\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for k in range(training_period):\n",
    "        #print(\"k is:\",k)\n",
    "        total_batch = int(train_feature.shape[0]/batch_size)\n",
    "        # Loop over all batches\n",
    "        batch_x = next_batch(k,batch_size,train_feature)\n",
    "        batch_y = next_batch(k,batch_size,train_label_one_hot)\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        sess.run(optimizer,feed_dict={x:batch_x,y:batch_y,keep_prob:0.9})\n",
    "        # Display logs per epoch step\n",
    "        if k % display_step == 0:\n",
    "            correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            \n",
    "            test_accuracy = accuracy.eval({x: test_feature, y: test_label_one_hot,keep_prob:1})\n",
    "            train_accuarcy = accuracy.eval({x: train_feature, y: train_label_one_hot,keep_prob:1})\n",
    "            print(\"period %d\" %k,\"trian:\", train_accuarcy, \"test:\" ,test_accuracy)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    # get accuarcy\n",
    "    test_accuracy = accuracy.eval({x: test_feature, y: test_label_one_hot,keep_prob:1})\n",
    "    train_accuarcy = accuracy.eval({x: train_feature, y: train_label_one_hot,keep_prob:1})\n",
    "    \n",
    "    test_acc = sess.run(accuracy,feed_dict={x: test_feature, y: test_label_one_hot,keep_prob:1.0})\n",
    "    train_acc = sess.run(accuracy,feed_dict={x: test_feature, y: test_label_one_hot,keep_prob:1.0})\n",
    "    # get probability matrix\n",
    "    soft_y = tf.nn.softmax(pred)\n",
    "    test_pred_prob_matrix = sess.run(soft_y,feed_dict={x: test_feature,keep_prob:1.0})\n",
    "    train_pred_prob_matrix = sess.run(soft_y,feed_dict={x: train_feature,keep_prob:1.0})\n",
    "    \n",
    "    # get predicted index\n",
    "    test_pred_index = sess.run(tf.argmax(pred, 1), feed_dict={x: test_feature,keep_prob:1.0})\n",
    "    train_pred_index = sess.run(tf.argmax(pred, 1), feed_dict={x: train_feature,keep_prob:1.0})\n",
    "    \n",
    "    # get predicted label\n",
    "    test_pred_label_array = fake_label_to_real_label_array(np.array(test_pred_index.tolist()), labels) #list form\n",
    "    train_pred_label_array = fake_label_to_real_label_array(np.array(train_pred_index.tolist()), labels) #list form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we get accuracy of 98.5. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
